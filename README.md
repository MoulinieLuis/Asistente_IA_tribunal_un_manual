# ğŸ“š Asistente Inteligente de Consulta JurÃ­dica

## ğŸ“Œ DescripciÃ³n General
Este proyecto es un **asistente de consultas jurÃ­dicas** que combina:
1. **Un motor semÃ¡ntico** que busca informaciÃ³n relevante en manuales oficiales del tribunal.
2. **Un modelo de IA** que genera respuestas completas y coherentes basadas en la informaciÃ³n encontrada y en la pregunta del usuario.

El objetivo es proporcionar respuestas precisas y fundamentadas, integrando **conocimiento humano (manuales)** con **capacidad generativa de IA**.

---

## âš™ï¸ Funcionamiento General

1. **RecepciÃ³n de la pregunta**
   - Un usuario envÃ­a su consulta a la API del proyecto.

2. **BÃºsqueda semÃ¡ntica**
   - El motor semÃ¡ntico analiza la pregunta y encuentra fragmentos relevantes en los manuales del tribunal.
    - Los fragmentos e los manuales ya se encunetran disponibles en el GitHub, fuern creados a parir del uso de FAISS junto con SentenceTransformer
   - AdemÃ¡s se utiliza **FAISS** como Ã­ndice vectorial para buscar por similitud de significado.

3. **GeneraciÃ³n de respuesta**
   - El contexto relevante (texto de manuales) y la pregunta se envÃ­an al **modelo de IA local**.
   - La IA combina la informaciÃ³n encontrada con su propio conocimiento para generar una respuesta clara.

4. **DevoluciÃ³n al usuario**
   - La respuesta final se envÃ­a en formato JSON.

---

## ğŸ§© Componentes del Proyecto

- **`main.py`**  
  Contiene la API desarrollada en **FastAPI**.  
  Expone los endpoints para recibir consultas y devolver respuestas.

- **`semantic_engine.py`**  
  MÃ³dulo que maneja la bÃºsqueda semÃ¡ntica usando FAISS y embeddings.

- **`ia_connector.py`**  
  MÃ³dulo que gestiona la conexiÃ³n con el modelo de IA local.

- **`procesamiento_manual.py`**  
  MÃ³dulo que procesa nuevos manuales que quieran ser integrados o utilizados una Ãºnica vez.
  *Se debe ejcutar el siguiente comando antes de utilizar el mÃ³dulo y el nuevo o los nuevos manuales ya deben existir en la carpeta personalized_manuals*
      **pip install sentence-transformers faiss-cpu**


- **`requirements.txt`**  
  Lista de dependencias necesarias para instalar el entorno.

- **`data/`**
  Carpeta donde se almacenan los manuales del tribunal en **texto plano** para ser indexados.

- **`personalized_manuals/`** *(Solo si se usarÃ¡ el mÃ³dulo proesamiento_manual)*
  Carpeta donde se almacenan nuevos manuales del tribunal en **texto plano** para ser indexados que no existen en la carpeta data.
---
## ğŸ–¥ï¸ Requerimientos del Sistema

- **Python** 3.9 o superior  
- **FastAPI** y **Uvicorn** para la API  
- **FAISS** para bÃºsqueda semÃ¡ntica  
- **SentenceTransformers** para embeddings  
- **Transformers** y modelo local compatible  
- Sistema operativo: Windows  
- Al menos **8 GB de RAM** (recomendado 16 GB si se utiliza un modelo superior o mÃ¡s potente)  
- GPU con soporte CUDA *(opcional pero recomendado)*

---
## Estructura de proyecto
Backend
â”œâ”€â”€ main.py                   # API FastAPI
â”œâ”€â”€ procesamiento_manual.py   # Documento que prepara la informaciÃ³n que el asistente luego usa para responder.
â”œâ”€â”€ semantic_engine.py        # Motor semÃ¡ntico (FAISS + embeddings)
â”œâ”€â”€ ia_connector.py           # Conector a Ollama (IA local)
â”œâ”€â”€ requirements.txt          # Dependencias del proyecto
â”œâ”€â”€ data/                     # Carpeta con manuales o documentos
â”œâ”€â”€ requirements.txt          # Dependencias del proyecto
â”œâ”€â”€ embeddings/               # TransformaciÃ³n de los manuales data en archivos de texto plano, procesados por FAISS
â”œâ”€â”€ img/                      # Imagen que representa el flujo de trabajo de la API main   
â””â”€â”€ __pycache__/              # Carpeta generada por Python que contiene el cÃ³digo compilado en bytecode
Frontend            
â””â”€â”€ index.html                #PÃ¡gina web de prueba local, puede ejecutarse con la extenciÃ³n VS code 'Live Preview'
README.md                     # DocumentaciÃ³n general


---
## ğŸ“¦ InstalaciÃ³n

1. **Clonar el repositorio**
   Desde gitbash

   git clone https://github.com/MoulinieLuis/Asistente_IA_Tribunal.git
   cd asistente-juridico

2. **Crear entorno virtual**
  python -m venv venv
  source venv/bin/activate   # En Windows: venv\Scripts\activate

3. **Instalar dependencias**
  pip install -r requirements.txt


4. **Indexar manuales (opcional si ya existe el Ã­ndice)**
  python semantic_engine.py --index


---
## ğŸš€ EjecuciÃ³n principal

1. **Iniciar la API con recarga automÃ¡tica:**
  uvicorn main:app --reload


**La API de IA existe cuando se descaga la aplicaciÃ³n Ollama y se instala la IA "Mistral"**
  Puerto (localhost): http://127.0.0.1:8000


---
## ğŸš€ EjecuciÃ³n para procesamiento manual

1. **Ejeuta el script:**
  python manual_processor.py

  *Los nuevos manuales ya deben existir en la carpeta personalized_manuals*


**La API de IA existe cuando se descaga la aplicaciÃ³n Ollama y se instala la IA "Mistral"**
  Puerto (localhost): http://127.0.0.1:8000



---
**Respuesta en formato JSON:**

{
  "answer": "SegÃºn el manual del tribunal, el procedimiento para apelar...",
  "source": "Manual de Procedimientos, CapÃ­tulo 4"
}

---
## ğŸ‘¥ ColaboraciÃ³n

**Para contribuir:**

Crear una nueva rama.

Realizar cambios y pruebas.

Hacer un Pull Request con una descripciÃ³n clara de las modificaciones.

---
## ğŸ”€ Flujo general del proyecto

![Arquitectura del Proyecto](/Backend/img/arquitectura_proyecto_asistente.png)